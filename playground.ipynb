{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aicenter/pyven/pytorch/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2022-12-22 06:31:05.310864: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-22 06:31:05.456035: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-12-22 06:31:06.321046: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/src/cdf38_1-dist/lib:/opt/x265/lib:/opt/cloudcompare/lib64:/opt/colmap-3.6/lib:/opt/benchmark-1.5.4.20/lib64:/opt/cuda-11.2/lib64:/opt/ceres-solver/lib64:/opt/cgal-5.2.2/lib64:/opt/boost-1.76.0/lib:/opt/python3/lib:/opt/src/cdf38_1-dist/lib:/opt/x265/lib:/opt/cloudcompare/lib64:/opt/colmap-3.6/lib:/opt/benchmark-1.5.4.20/lib64:/opt/cuda-11.2/lib64:/opt/ceres-solver/lib64:/opt/cgal-5.2.2/lib64:/opt/boost-1.76.0/lib:/opt/python3/lib:/opt/src/cdf38_1-dist/lib:/opt/x265/lib:/opt/cloudcompare/lib64:/opt/colmap-3.6/lib:/opt/benchmark-1.5.4.20/lib64:/opt/cuda-11.2/lib64:/opt/ceres-solver/lib64:/opt/cgal-5.2.2/lib64:/opt/boost-1.76.0/lib:/opt/python3/lib:/lib64:/lib\n",
      "2022-12-22 06:31:06.321126: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/src/cdf38_1-dist/lib:/opt/x265/lib:/opt/cloudcompare/lib64:/opt/colmap-3.6/lib:/opt/benchmark-1.5.4.20/lib64:/opt/cuda-11.2/lib64:/opt/ceres-solver/lib64:/opt/cgal-5.2.2/lib64:/opt/boost-1.76.0/lib:/opt/python3/lib:/opt/src/cdf38_1-dist/lib:/opt/x265/lib:/opt/cloudcompare/lib64:/opt/colmap-3.6/lib:/opt/benchmark-1.5.4.20/lib64:/opt/cuda-11.2/lib64:/opt/ceres-solver/lib64:/opt/cgal-5.2.2/lib64:/opt/boost-1.76.0/lib:/opt/python3/lib:/opt/src/cdf38_1-dist/lib:/opt/x265/lib:/opt/cloudcompare/lib64:/opt/colmap-3.6/lib:/opt/benchmark-1.5.4.20/lib64:/opt/cuda-11.2/lib64:/opt/ceres-solver/lib64:/opt/cgal-5.2.2/lib64:/opt/boost-1.76.0/lib:/opt/python3/lib:/lib64:/lib\n",
      "2022-12-22 06:31:06.321134: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import datasets\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import evaluate\n",
    "import transformers\n",
    "from accelerate import Accelerator\n",
    "from accelerate.logging import get_logger\n",
    "from accelerate.utils import set_seed\n",
    "from huggingface_hub import Repository\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    "    PretrainedConfig,\n",
    "    SchedulerType,\n",
    "    default_data_collator,\n",
    "    get_scheduler,\n",
    ")\n",
    "from transformers.utils import check_min_version, get_full_repo_name, send_example_telemetry\n",
    "from transformers.utils.versions import require_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|██████████| 28.8k/28.8k [00:00<00:00, 143kB/s] \n",
      "Downloading metadata: 100%|██████████| 28.7k/28.7k [00:00<00:00, 142kB/s] \n",
      "Downloading readme: 100%|██████████| 27.8k/27.8k [00:00<00:00, 138kB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset glue/sst2 to /home/aicenter/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 7.44M/7.44M [00:06<00:00, 1.12MB/s]\n",
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset glue downloaded and prepared to /home/aicenter/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 1724.40it/s]\n"
     ]
    }
   ],
   "source": [
    "raw_datasets = load_dataset(\"glue\", \"sst2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassLabel(names=['negative', 'positive'], id=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets['train'].features[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-22b9ae19f86e1df3\n",
      "Found cached dataset json (/home/aicenter/.cache/huggingface/datasets/json/default-22b9ae19f86e1df3/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab)\n",
      "100%|██████████| 1/1 [00:00<00:00, 1312.77it/s]\n"
     ]
    }
   ],
   "source": [
    "data_files = {}\n",
    "data_files[\"train\"] = './true-false-qa.json'\n",
    "cus_raw_datasets = load_dataset('json', data_files=data_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['id', 'answer', 'question'],\n",
       "         num_rows: 2161\n",
       "     })\n",
       " }),\n",
       " DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['sentence', 'label', 'idx'],\n",
       "         num_rows: 67349\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['sentence', 'label', 'idx'],\n",
       "         num_rows: 872\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['sentence', 'label', 'idx'],\n",
       "         num_rows: 1821\n",
       "     })\n",
       " }))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cus_raw_datasets, raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Value(dtype='string', id=None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cus_raw_datasets[\"train\"].features[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': 'hide new secretions from the parental units ',\n",
       " 'label': 0,\n",
       " 'idx': 0}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id', 'answer', 'question']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_label_column_names = [name for name in cus_raw_datasets[\"train\"].column_names if name != \"label\"]\n",
    "non_label_column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "A = json.load(open('./true-false-qa.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify(obj):\n",
    "    obj['sentence'] = (obj['question'])\n",
    "    obj['label'] = int(obj['answer'])\n",
    "    obj['idx'] = int(obj['id'])\n",
    "    del obj['question']\n",
    "    del obj['answer']\n",
    "    del obj['id']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in A:\n",
    "    modify(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data_json = A[:len(A)//10]\n",
    "train_data_json = A[len(A)//10:]\n",
    "\n",
    "json.dump(valid_data_json, open('./TF-random-valid.json', 'w'), indent=2, ensure_ascii=False)\n",
    "json.dump(train_data_json, open('./TF-random-train.json', 'w'), indent=2, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxL = 0\n",
    "\n",
    "for a in A:\n",
    "    if len(a['sentence']) > maxL: maxL = len(a['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d04bdaebc4fff50cdd037fd9f1013949d2227a20ffff53ea4ef40f6824796415"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
